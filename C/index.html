<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Puter OS AI Â· Unified & Live</title>
    <script src="https://js.puter.com/v2/"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        /* --- CORE DESIGN SYSTEM (Apple TV / Glassmorphism) --- */
        :root {
            --bg-color: #000000;
            --glass-panel: rgba(28, 28, 30, 0.75);
            --glass-border: rgba(255, 255, 255, 0.12);
            --accent-blue: #0A84FF;
            --accent-green: #30D158; /* Call Green */
            --accent-red: #FF453A;   /* Hangup Red */
            --accent-amber: #FF9F0A; /* Mic Active */
            --text-primary: #FFFFFF;
            --text-secondary: rgba(235, 235, 245, 0.6);
            --blur-strength: 50px;
            --font-stack: -apple-system, BlinkMacSystemFont, "SF Pro Text", "Segoe UI", Roboto, sans-serif;
        }

        body {
            font-family: var(--font-stack);
            background-color: var(--bg-color);
            background-image: 
                radial-gradient(circle at 10% 20%, rgba(10, 132, 255, 0.15) 0%, transparent 50%),
                radial-gradient(circle at 90% 80%, rgba(48, 209, 88, 0.1) 0%, transparent 50%);
            margin: 0;
            height: 100vh;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            color: var(--text-primary);
        }

        /* --- MAIN APP WINDOW --- */
        .app-container {
            width: 95%;
            max-width: 1000px;
            height: 92vh;
            background: var(--glass-panel);
            backdrop-filter: blur(var(--blur-strength));
            -webkit-backdrop-filter: blur(var(--blur-strength));
            border-radius: 24px;
            border: 1px solid var(--glass-border);
            display: flex;
            flex-direction: column;
            box-shadow: 0 40px 80px rgba(0,0,0,0.6);
            position: relative;
            overflow: hidden;
        }

        /* --- HEADER --- */
        .header {
            padding: 20px 30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid var(--glass-border);
            background: rgba(255, 255, 255, 0.03);
            z-index: 10;
        }

        .header h1 {
            font-size: 1.1rem;
            font-weight: 600;
            margin: 0;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        select {
            appearance: none;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-primary);
            border: 1px solid var(--glass-border);
            padding: 8px 30px 8px 15px;
            border-radius: 12px;
            font-family: var(--font-stack);
            font-size: 0.85rem;
            cursor: pointer;
            outline: none;
        }
        
        select optgroup { color: #000; background: #fff; }

        /* --- CHAT SCROLL AREA --- */
        .chat-area {
            flex-grow: 1;
            padding: 30px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 20px;
            scroll-behavior: smooth;
        }
        .chat-area::-webkit-scrollbar { width: 0px; } /* Hide scrollbar for cleaner look */

        .message {
            max-width: 80%;
            padding: 14px 20px;
            border-radius: 22px;
            font-size: 1rem;
            line-height: 1.5;
            animation: popIn 0.3s ease-out;
        }

        @keyframes popIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .user-message {
            align-self: flex-end;
            background: var(--accent-blue);
            color: white;
            border-bottom-right-radius: 4px;
        }

        .ai-message {
            align-self: flex-start;
            background: rgba(255, 255, 255, 0.1);
            color: var(--text-primary);
            border-bottom-left-radius: 4px;
        }

        /* --- BOTTOM CONTROLS --- */
        .controls-area {
            padding: 20px 30px;
            background: rgba(0, 0, 0, 0.3);
            border-top: 1px solid var(--glass-border);
            display: flex;
            flex-direction: column;
            gap: 15px;
            z-index: 10;
        }

        /* Input Row */
        .input-row {
            display: flex;
            gap: 15px;
            align-items: center;
        }

        .input-wrapper {
            flex-grow: 1;
            position: relative;
        }

        input[type="text"] {
            width: 100%;
            background: rgba(255, 255, 255, 0.08);
            border: none;
            padding: 16px 20px;
            border-radius: 18px;
            color: white;
            font-size: 1rem;
            outline: none;
            box-sizing: border-box;
        }

        #send-btn {
            background: rgba(255,255,255,0.15);
            color: white;
            border: none;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            cursor: pointer;
            transition: 0.2s;
        }
        #send-btn:hover { background: var(--accent-blue); }

        /* Call Button Row */
        .action-row {
            display: flex;
            justify-content: center;
        }

        #start-call-btn {
            background: var(--accent-green);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 30px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 10px;
            box-shadow: 0 4px 15px rgba(48, 209, 88, 0.3);
            transition: transform 0.2s, background 0.2s;
        }

        #start-call-btn:hover {
            transform: scale(1.05);
            background: #28c04d;
        }

        /* --- LIVE CALL OVERLAY (THE PHONE MODE) --- */
        .live-mode-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.85); /* Darker background */
            backdrop-filter: blur(60px);
            z-index: 100;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.5s ease;
        }

        .live-mode-overlay.active {
            opacity: 1;
            pointer-events: all;
        }

        /* The Glowing Orb */
        .orb-container {
            position: relative;
            width: 200px;
            height: 200px;
            display: flex;
            justify-content: center;
            align-items: center;
            margin-bottom: 50px;
        }

        .orb {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: white;
            box-shadow: 0 0 60px 20px rgba(255,255,255,0.5);
            transition: all 0.5s ease;
        }

        /* Orb States */
        .orb.listening {
            background: var(--accent-amber);
            box-shadow: 0 0 80px 30px rgba(255, 159, 10, 0.4);
            animation: breathe 2s infinite ease-in-out;
        }

        .orb.speaking {
            background: var(--accent-blue);
            box-shadow: 0 0 80px 30px rgba(10, 132, 255, 0.4);
            animation: pulse-speak 0.8s infinite alternate;
        }

        .orb.processing {
            background: #fff;
            transform: scale(0.8);
            opacity: 0.7;
        }

        @keyframes breathe {
            0%, 100% { transform: scale(1); opacity: 0.8; }
            50% { transform: scale(1.1); opacity: 1; }
        }

        @keyframes pulse-speak {
            from { transform: scale(1); }
            to { transform: scale(1.2); }
        }

        .live-status-text {
            font-size: 1.5rem;
            font-weight: 500;
            color: rgba(255,255,255,0.9);
            margin-bottom: 10px;
        }

        .live-subtext {
            font-size: 0.9rem;
            color: rgba(255,255,255,0.5);
        }

        #hangup-btn {
            margin-top: 60px;
            width: 70px;
            height: 70px;
            border-radius: 50%;
            background: var(--accent-red);
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
            box-shadow: 0 5px 20px rgba(255, 69, 58, 0.4);
            transition: transform 0.2s;
        }
        #hangup-btn:hover { transform: scale(1.1); }

    </style>
</head>
<body>

<div class="app-container">
    
    <div class="header">
        <h1><i class="fa-brands fa-apple"></i> Puter AI</h1>
        <select id="model-select">
            <optgroup label="Google Gemini (Recommended)">
                <option value="gemini-1.5-pro">Gemini 1.5 Pro (Best Logic)</option>
                <option value="gemini-1.5-flash">Gemini 1.5 Flash (Fastest)</option>
                <option value="gemini-2.0-flash-exp">Gemini 2.0 Flash (Experimental)</option>
            </optgroup>
            <optgroup label="OpenAI GPT">
                <option value="gpt-4o" selected>GPT-4o (Omni - Best Overall)</option>
                <option value="gpt-4o-mini">GPT-4o Mini (Fast)</option>
                <option value="gpt-4-turbo">GPT-4 Turbo</option>
                <option value="gpt-3.5-turbo">GPT-3.5 Turbo</option>
            </optgroup>
            <optgroup label="Anthropic & Others">
                <option value="claude-3-5-sonnet">Claude 3.5 Sonnet</option>
                <option value="claude-3-opus">Claude 3 Opus</option>
                <option value="mistral-large-latest">Mistral Large</option>
            </optgroup>
        </select>
    </div>

    <div class="chat-area" id="chat-feed">
        <div class="message ai-message">
            Hello. Select a model above. You can type below, or press <strong>Start Live Call</strong> for a hands-free voice experience.
        </div>
    </div>

    <div class="controls-area">
        <div class="input-row">
            <div class="input-wrapper">
                <input type="text" id="user-input" placeholder="Type a message..." autocomplete="off">
            </div>
            <button id="send-btn"><i class="fa-solid fa-arrow-up"></i></button>
        </div>
        
        <div class="action-row">
            <button id="start-call-btn">
                <i class="fa-solid fa-phone"></i> Start Live Call
            </button>
        </div>
    </div>

    <div class="live-mode-overlay" id="live-overlay">
        <div class="orb-container">
            <div class="orb" id="live-orb"></div>
        </div>
        <div class="live-status-text" id="live-status">Connecting...</div>
        <div class="live-subtext" id="live-model-name">Using GPT-4o</div>
        
        <button id="hangup-btn" title="End Call">
            <i class="fa-solid fa-phone-slash"></i>
        </button>
    </div>

</div>

<script>
    // --- CONFIG & STATE ---
    const UI = {
        chatFeed: document.getElementById('chat-feed'),
        input: document.getElementById('user-input'),
        sendBtn: document.getElementById('send-btn'),
        startCallBtn: document.getElementById('start-call-btn'),
        modelSelect: document.getElementById('model-select'),
        
        // Live Mode UI
        overlay: document.getElementById('live-overlay'),
        orb: document.getElementById('live-orb'),
        status: document.getElementById('live-status'),
        subStatus: document.getElementById('live-model-name'),
        hangupBtn: document.getElementById('hangup-btn')
    };

    let state = {
        isLiveMode: false,     // Are we in the phone call screen?
        isAiSpeaking: false,   // Is the AI currently talking?
        recognition: null,     // The Speech Object
        audioPlayer: null,     // The Audio Object
        selectedModel: 'gpt-4o'
    };

    // --- INITIALIZATION ---
    window.addEventListener('load', () => {
        initSpeechRecognition();
    });

    // --- SPEECH RECOGNITION SETUP (Web Speech API) ---
    function initSpeechRecognition() {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
            alert("Your browser does not support voice input. Please use Chrome/Edge/Safari.");
            UI.startCallBtn.style.display = 'none';
            return;
        }

        state.recognition = new SpeechRecognition();
        state.recognition.continuous = false; // We want to process sentence by sentence
        state.recognition.interimResults = false;
        state.recognition.lang = 'en-US';

        // 1. When user starts speaking
        state.recognition.onstart = () => {
            if (state.isLiveMode) {
                setLiveVisuals('listening');
            }
        };

        // 2. When user stops speaking (silence detected)
        state.recognition.onend = () => {
            // CRITICAL LOOP LOGIC:
            // If we are in Live Mode AND the AI isn't currently talking,
            // we must immediately restart the microphone to keep the "call" open.
            if (state.isLiveMode && !state.isAiSpeaking) {
                try {
                    state.recognition.start();
                } catch (e) { /* Ignore "already started" errors */ }
            } else if (state.isLiveMode && state.isAiSpeaking) {
                // If AI is speaking, do nothing. We wait for audio to finish.
                setLiveVisuals('speaking'); 
            }
        };

        // 3. When text is captured
        state.recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            if (transcript.trim()) {
                handleUserMessage(transcript);
            }
        };
    }

    // --- MAIN LOGIC ---

    async function handleUserMessage(text) {
        state.selectedModel = UI.modelSelect.value;
        const modelName = UI.modelSelect.options[UI.modelSelect.selectedIndex].text;

        // Visuals update
        if (state.isLiveMode) {
            setLiveVisuals('processing');
        } else {
            addChatMessage(text, 'user');
            addChatMessage('Thinking...', 'ai', modelName, 'temp-loading');
        }

        try {
            // 1. Call Puter AI
            // We use non-streaming for the call mode to get full text for TTS
            const response = await puter.ai.chat(text, { model: state.selectedModel });
            const aiText = response.message.content;

            // 2. Handle Response
            if (state.isLiveMode) {
                // In Live Mode: Speak it, don't show text
                speakResponse(aiText);
            } else {
                // In Chat Mode: Show text
                document.getElementById('temp-loading').remove();
                addChatMessage(aiText, 'ai', modelName);
            }

        } catch (err) {
            console.error(err);
            if (state.isLiveMode) speakResponse("I'm sorry, I lost connection.");
        }
    }

    // --- TTS (TEXT TO SPEECH) & LOOPING ---
    async function speakResponse(text) {
        state.isAiSpeaking = true;
        setLiveVisuals('speaking');

        try {
            // Stop mic while AI generates audio
            state.recognition.stop(); 

            state.audioPlayer = await puter.ai.txt2speech(text, {
                model: 'gpt-4o-mini-tts',
                voice: 'alloy'
            });

            state.audioPlayer.play();

            // When AI finishes talking -> TURN MIC BACK ON
            state.audioPlayer.onended = () => {
                state.isAiSpeaking = false;
                if (state.isLiveMode) {
                    setLiveVisuals('listening');
                    try { state.recognition.start(); } catch(e){}
                }
            };

        } catch (e) {
            console.error("TTS Error", e);
            state.isAiSpeaking = false;
        }
    }

    // --- UI FUNCTIONS ---

    // Switch between Orb States
    function setLiveVisuals(mode) {
        // Reset classes
        UI.orb.className = 'orb';
        
        if (mode === 'listening') {
            UI.orb.classList.add('listening');
            UI.status.innerText = "Listening...";
            UI.status.style.color = "#FF9F0A"; // Amber
        } else if (mode === 'speaking') {
            UI.orb.classList.add('speaking');
            UI.status.innerText = "Speaking...";
            UI.status.style.color = "#0A84FF"; // Blue
        } else if (mode === 'processing') {
            UI.orb.classList.add('processing');
            UI.status.innerText = "Thinking...";
            UI.status.style.color = "white";
        }
    }

    function addChatMessage(text, sender, modelName = null, id = null) {
        const div = document.createElement('div');
        div.className = `message ${sender}-message`;
        if(id) div.id = id;
        
        // Simple Markdown bold parsing
        div.innerHTML = text.replace(/\*\*(.*?)\*\*/g, '<b>$1</b>').replace(/\n/g, '<br>');
        
        if (modelName && sender === 'ai') {
            const meta = document.createElement('div');
            meta.style.fontSize = '0.75rem';
            meta.style.marginTop = '5px';
            meta.style.opacity = '0.6';
            meta.innerText = modelName;
            div.appendChild(meta);
        }

        UI.chatFeed.appendChild(div);
        UI.chatFeed.scrollTop = UI.chatFeed.scrollHeight;
    }

    // --- EVENT LISTENERS ---

    // 1. Send Button (Text Mode)
    UI.sendBtn.addEventListener('click', () => {
        const text = UI.input.value;
        if(text) {
            UI.input.value = '';
            handleUserMessage(text);
        }
    });

    UI.input.addEventListener('keypress', (e) => {
        if (e.key === 'Enter') UI.sendBtn.click();
    });

    // 2. START CALL
    UI.startCallBtn.addEventListener('click', () => {
        state.isLiveMode = true;
        UI.overlay.classList.add('active');
        UI.subStatus.innerText = "Using " + UI.modelSelect.options[UI.modelSelect.selectedIndex].text;
        
        // Start listening immediately
        setLiveVisuals('listening');
        try { state.recognition.start(); } catch(e){}
    });

    // 3. END CALL (Hang Up)
    UI.hangupBtn.addEventListener('click', () => {
        state.isLiveMode = false;
        UI.overlay.classList.remove('active');
        
        // Stop audio and mic
        if (state.audioPlayer) {
            state.audioPlayer.pause();
            state.audioPlayer = null;
        }
        state.recognition.stop();
        state.isAiSpeaking = false;
    });

</script>
</body>
</html>
